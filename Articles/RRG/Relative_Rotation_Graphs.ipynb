{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm #Used in the for loops to track the progress of the loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Data Folder\n",
    "Data_folder = os.path.abspath(os.getcwd() +'/Data/')\n",
    "if not os.path.exists(Data_folder):\n",
    "    os.makedirs(Data_folder)\n",
    "\n",
    "#Clean older files and folders in the Data Folder\n",
    "filelist = [ f for f in os.listdir(Data_folder)]\n",
    "for f in filelist:\n",
    "    shutil.rmtree(os.path.join(Data_folder, f), ignore_errors=True)\n",
    "\n",
    "filelist = [ f for f in os.listdir(Data_folder)]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(Data_folder, f))\n",
    "\n",
    "#Create New Folder for Stock Indices\n",
    "stock_indices_folder = os.path.join(Data_folder, 'Stock Indices')\n",
    "if not os.path.exists(stock_indices_folder):\n",
    "    os.makedirs(stock_indices_folder)\n",
    "    \n",
    "#Create New Folder for FX Rates\n",
    "FX_rates_folder = os.path.join(Data_folder, 'FX Rates')\n",
    "if not os.path.exists(FX_rates_folder):\n",
    "    os.makedirs(FX_rates_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Indices and Currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the Indices data\n",
    "indices_data = pd.read_csv('Stock_Indices.csv') \n",
    "\n",
    "#Create Indices variables and Manage the Column Data to create new variables\n",
    "indices_tickers = indices_data['Yahoo Symbol']\n",
    "\n",
    "FX_rates_symbols = indices_data['Yahoo Currency Symbol']\n",
    "FX_rates_symbols = FX_rates_symbols.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Indices Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price Data: Defining the Start and End dates \n",
    "finishing_period = time.strftime('%d/%m/%Y')\n",
    "\n",
    "    ##Let's define the start date as 1 year ago\n",
    "beginning_period_unformat = datetime.datetime.strptime(finishing_period, '%d/%m/%Y') - datetime.timedelta(days=370)\n",
    "beginning_period = beginning_period_unformat.strftime('%m/%d/%Y')\n",
    "\n",
    "for ticker in tqdm(indices_tickers):\n",
    "    try:\n",
    "\n",
    "        historical_data = get_data(ticker, start_date = beginning_period , end_date = finishing_period)\n",
    "\n",
    "        #Let's Create a DataFrame with the downloaded Data\n",
    "        df = pd.DataFrame(historical_data, columns=['open', 'high', 'low', 'close', 'adjclose', 'volume'])\n",
    "        df['date'] = pd.to_datetime(df.index, format='%Y/%m/%d')\n",
    "\n",
    "        close_price = df.close.values\n",
    "\n",
    "        #Construct Ticker Table to Print\n",
    "        index_data_table = pd.DataFrame(data={'date': df['date'], ticker: df['close']}).set_index('date')\n",
    "\n",
    "        index_data_table = index_data_table.reset_index()\n",
    "        index_data_table.sort_values(by='date', inplace=True, ascending=False)\n",
    "        index_data_table = index_data_table.set_index('date')\n",
    "        index_data_table.to_csv(os.path.join(stock_indices_folder,ticker)+'_Table.csv')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join All the Ticker Data Files into a Table\n",
    "files= os.listdir(stock_indices_folder)\n",
    "\n",
    "indices_data_table = pd.read_csv(os.path.join(stock_indices_folder,files[0]))\n",
    "\n",
    "for file in files[1:]:\n",
    "    df = pd.read_csv(os.path.join(stock_indices_folder,file)) \n",
    "    indices_data_table = indices_data_table.merge(df, on='date', how='left')\n",
    "\n",
    "#Rearrange the DataFrame format: fill na's, rounding, etc.\n",
    "indices_data_table = indices_data_table.fillna(method='bfill')\n",
    "indices_data_table = indices_data_table.round(2)\n",
    "indices_data_table = indices_data_table.set_index('date')\n",
    "indices_data_table = indices_data_table.head(-1)\n",
    "\n",
    "indices_data_table.to_csv(os.path.join(Data_folder,'Stock_Indices_Data_Table.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price Data: Defining the Start and End dates \n",
    "finishing_period = time.strftime('%d/%m/%Y')\n",
    "\n",
    "    ##Let's define the start date as 1 year ago\n",
    "beginning_period_unformat = datetime.datetime.strptime(finishing_period, '%d/%m/%Y') - datetime.timedelta(days=370)\n",
    "beginning_period = beginning_period_unformat.strftime('%m/%d/%Y')\n",
    "\n",
    "for symbol in tqdm(FX_rates_symbols):\n",
    "    try:\n",
    "\n",
    "        historical_data = get_data(symbol, start_date = beginning_period , end_date = finishing_period)\n",
    "\n",
    "        #Let's Create a DataFrame with the downloaded Data\n",
    "        df = pd.DataFrame(historical_data, columns=['open', 'high', 'low', 'close', 'adjclose', 'volume'])\n",
    "        df['date'] = pd.to_datetime(df.index, format='%Y/%m/%d')\n",
    "\n",
    "        close_price = df.close.values\n",
    "        \n",
    "        symbol = symbol[:6]\n",
    "        #Construct Ticker Table to Print\n",
    "        currency_data_table = pd.DataFrame(data={'date': df['date'], symbol: df['close']}).set_index('date')\n",
    "\n",
    "        currency_data_table = currency_data_table.reset_index()\n",
    "        currency_data_table.sort_values(by='date', inplace=True, ascending=False)\n",
    "        currency_data_table = currency_data_table.set_index('date')\n",
    "        currency_data_table.to_csv(os.path.join(FX_rates_folder,symbol)+'_Table.csv')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join All the Currencies Data Files into a Table\n",
    "files= os.listdir(FX_rates_folder)\n",
    "\n",
    "currencies_data_table = pd.read_csv(os.path.join(FX_rates_folder,files[0]))\n",
    "\n",
    "for file in files[1:]:\n",
    "    df = pd.read_csv(os.path.join(FX_rates_folder,file)) \n",
    "    currencies_data_table = currencies_data_table.merge(df, on='date', how='left')\n",
    "\n",
    "#Rearrange the DataFrame format: fill na's, rounding, etc.\n",
    "currencies_data_table = currencies_data_table.fillna(method='bfill')\n",
    "currencies_data_table = currencies_data_table.set_index('date')\n",
    "currencies_data_table = currencies_data_table.head(-1)\n",
    "\n",
    "currencies_data_table.to_csv(os.path.join(Data_folder,'FX_rates_Data_Table.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Table Indices Tickers based on same Currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge Indices data with Currencies Data\n",
    "indices_currencies_data_table = indices_data_table.merge(currencies_data_table,on='date', how='left')\n",
    "indices_currencies_data_table = indices_currencies_data_table.fillna(method='bfill')\n",
    "indices_currencies_data_table['USDUSD'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Indices' values to same base Currency (USD) for proper comparison analysis\n",
    "for ticker in indices_tickers:\n",
    "    if indices_data[indices_data['Yahoo Symbol'] == ticker]['Yahoo Currency Symbol'].isnull().iloc[0]:\n",
    "        currency = 'USDUSD'\n",
    "    else:\n",
    "        currency = indices_data[indices_data['Yahoo Symbol'] == ticker]['Yahoo Currency Symbol'].iloc[0][:6]\n",
    "    indices_currencies_data_table[ticker] = indices_currencies_data_table[ticker]*indices_currencies_data_table[currency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limit the DataFrame to include just the Stock Indices (converted)\n",
    "currencies = []\n",
    "for currency in FX_rates_symbols:\n",
    "    currency = currency[:6]\n",
    "    currencies.append(currency)\n",
    "\n",
    "indices_currencies_data_table = indices_currencies_data_table.drop(columns = currencies).drop(columns = ['USDUSD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Metrics used in RRG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate JdK- RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_currencies_data_table.sort_values(by='date', inplace=True, ascending=True)\n",
    "\n",
    "#Calculate the 1-day Returns for the Indices\n",
    "indices_currencies_data_table = indices_currencies_data_table.pct_change(1)\n",
    "\n",
    "#Calculate the Indices' value on and Index-Base (100) considering the calculated returns\n",
    "indices_currencies_data_table.iloc[0] = 100\n",
    "for ticker in indices_currencies_data_table.columns:\n",
    "    for i in range(1, len(indices_currencies_data_table[ticker])):\n",
    "        indices_currencies_data_table[ticker][i] = indices_currencies_data_table[ticker][i-1]*(1+indices_currencies_data_table[ticker][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Index for comparison (Benchamrk Index): FTSE Global Equity Index Series\n",
    "bechmark = 'VWRL.AS'\n",
    "benchmark_values = indices_currencies_data_table[bechmark]\n",
    "\n",
    "indices_currencies_data_table = indices_currencies_data_table.drop(columns = bechmark)\n",
    "\n",
    "#Calculate the relative Performance of the Index in relation to the Benchmark\n",
    "for ticker in indices_currencies_data_table.columns:   \n",
    "    indices_currencies_data_table[ticker] = indices_currencies_data_table[ticker]/benchmark_values - 1\n",
    "\n",
    "#Normalize the Values considering a 14-days Window (Note: 10 weekdays)\n",
    "for ticker in indices_currencies_data_table.columns: \n",
    "    indices_currencies_data_table[ticker] = 100 + ((indices_currencies_data_table[ticker] - indices_currencies_data_table[ticker].rolling(10).mean())/indices_currencies_data_table[ticker].rolling(10).std() + 1)\n",
    "    \n",
    "# Rouding and Exclusing NA's\n",
    "indices_currencies_data_table = indices_currencies_data_table.round(2).dropna()\n",
    "JDK_RS_ratio = indices_currencies_data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate JdK- RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the Momentum of the RS-ratio\n",
    "JDK_RS_momentum = JDK_RS_ratio.pct_change(10)\n",
    "\n",
    "#Normalize the Values considering a 14-days Window (Note: 10 weekdays)\n",
    "for ticker in JDK_RS_momentum.columns: \n",
    "    JDK_RS_momentum[ticker] = 100 + ((JDK_RS_momentum[ticker] - JDK_RS_momentum[ticker].rolling(10).mean())/JDK_RS_momentum[ticker].rolling(10).std() + 1)\n",
    "\n",
    "# Rounding and Excluding NA's\n",
    "JDK_RS_momentum = JDK_RS_momentum.round(2).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust DataFrames to be shown in Monthly terms\n",
    "JDK_RS_ratio = JDK_RS_ratio.reset_index()\n",
    "JDK_RS_ratio['date'] = pd.to_datetime(JDK_RS_ratio['date'], format='%Y-%m-%d')\n",
    "JDK_RS_ratio = JDK_RS_ratio.set_index('date')\n",
    "JDK_RS_ratio = JDK_RS_ratio.resample('M').ffill()\n",
    "\n",
    "#... now for JDK_RS Momentum\n",
    "JDK_RS_momentum = JDK_RS_momentum.reset_index()\n",
    "JDK_RS_momentum['date'] = pd.to_datetime(JDK_RS_momentum['date'], format='%Y-%m-%d')\n",
    "JDK_RS_momentum = JDK_RS_momentum.set_index('date')\n",
    "JDK_RS_momentum = JDK_RS_momentum.resample('M').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DataFrames for Creating the ScaterPlots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame for ScaterPlot showing multiple Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dictionary for renaming Columns\n",
    "columns_rename = dict(zip(indices_data['Yahoo Symbol'],indices_data['Symbol']))\n",
    "\n",
    "#Rename Columns according to the Symbols and not Yahoo Symbols\n",
    "JDK_RS_ratio = JDK_RS_ratio.rename(columns = columns_rename)\n",
    "JDK_RS_momentum = JDK_RS_momentum.rename(columns = columns_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Sub-Header to the DataFrame: 'JDK_RS_ratio' -> As later both RS_ratio and RS_momentum will be joint\n",
    "JDK_RS_ratio_subheader = pd.DataFrame(np.zeros((1,JDK_RS_ratio.columns.shape[0])),columns=JDK_RS_ratio.columns)\n",
    "JDK_RS_ratio_subheader.iloc[0] = 'JDK_RS_ratio'\n",
    "\n",
    "JDK_RS_ratio_total = pd.concat([JDK_RS_ratio_subheader, JDK_RS_ratio], axis=0)\n",
    "\n",
    "#... same for JDK_RS Momentum\n",
    "JDK_RS_momentum_subheader = pd.DataFrame(np.zeros((1,JDK_RS_momentum.columns.shape[0])),columns=JDK_RS_momentum.columns)\n",
    "JDK_RS_momentum_subheader.iloc[0] = 'JDK_RS_momentum'\n",
    "\n",
    "JDK_RS_momentum_total = pd.concat([JDK_RS_momentum_subheader, JDK_RS_momentum], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join both DataFrames\n",
    "RRG_df = pd.concat([JDK_RS_ratio_total, JDK_RS_momentum_total], axis=1, sort=True)\n",
    "RRG_df = RRG_df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for the Plotting\n",
    "from bokeh.plotting import figure, show, save\n",
    "from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.models.widgets import DataTable, TableColumn\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Scatter Plot with All Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame Just with the Last Period Metrics for Plotting the Scatter plot\n",
    "##Reduce JDK_RS_ratio to 1 (Last) Period\n",
    "JDK_RS_ratio_1P = pd.DataFrame(JDK_RS_ratio.iloc[-1].transpose())\n",
    "JDK_RS_ratio_1P = JDK_RS_ratio_1P.rename(columns= {JDK_RS_ratio_1P.columns[0]: 'JDK_RS_ratio'})\n",
    "\n",
    "##Reduce JDK_RS_momentum to 1 (Last) Period\n",
    "JDK_RS_momentum_1P = pd.DataFrame(JDK_RS_momentum.iloc[-1].transpose())\n",
    "JDK_RS_momentum_1P = JDK_RS_momentum_1P.rename(columns= {JDK_RS_momentum_1P.columns[0]: 'JDK_RS_momentum'})\n",
    "\n",
    "#Joining the 2 Dataframes\n",
    "JDK_RS_1P = pd.concat([JDK_RS_ratio_1P,JDK_RS_momentum_1P], axis=1)\n",
    "\n",
    "##Reset the Index so the Index's names are in the Scatter\n",
    "JDK_RS_1P = JDK_RS_1P.reset_index() \n",
    "order = [1,2,0] # setting column's order\n",
    "JDK_RS_1P = JDK_RS_1P[[JDK_RS_1P.columns[i] for i in order]]\n",
    "\n",
    "##Create a New Column with the Quadrants Indication\n",
    "JDK_RS_1P['Quadrant'] = JDK_RS_1P['index']\n",
    "for row in JDK_RS_1P['Quadrant'].index:\n",
    "    if JDK_RS_1P['JDK_RS_ratio'][row] > 100 and JDK_RS_1P['JDK_RS_momentum'][row] > 100:\n",
    "        JDK_RS_1P['Quadrant'][row] = 'Leading'\n",
    "    elif JDK_RS_1P['JDK_RS_ratio'][row] > 100 and JDK_RS_1P['JDK_RS_momentum'][row] < 100:\n",
    "        JDK_RS_1P['Quadrant'][row] = 'Lagging'\n",
    "    elif JDK_RS_1P['JDK_RS_ratio'][row] < 100 and JDK_RS_1P['JDK_RS_momentum'][row] < 100:\n",
    "        JDK_RS_1P['Quadrant'][row] = 'Weakening'\n",
    "    elif JDK_RS_1P['JDK_RS_ratio'][row] < 100 and JDK_RS_1P['JDK_RS_momentum'][row] > 100:\n",
    "        JDK_RS_1P['Quadrant'][row] = 'Improving'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scatter Plot\n",
    "scatter = hv.Scatter(JDK_RS_1P, kdims = ['JDK_RS_ratio', 'JDK_RS_momentum'])\n",
    "\n",
    "##Colors\n",
    "explicit_mapping = {'Leading': 'green', 'Lagging': 'yellow', 'Weakening': 'red', 'Improving': 'blue'}\n",
    "\n",
    "##Defining the Charts's Area\n",
    "x_max_distance = max(abs(int(JDK_RS_1P['JDK_RS_ratio'].min())-100), int(JDK_RS_1P['JDK_RS_ratio'].max())-100,\n",
    "                    abs(int(JDK_RS_1P['JDK_RS_momentum'].min())-100), int(JDK_RS_1P['JDK_RS_momentum'].max())-100)\n",
    "x_y_range = (100 - 1 - x_max_distance, 100 + 1 + x_max_distance)\n",
    "\n",
    "##Plot Joining all together\n",
    "scatter = scatter.opts(opts.Scatter(tools=['hover'], height = 500, width=500, size = 10, xlim = x_y_range, ylim = x_y_range,\n",
    "                                   color = 'Quadrant', cmap=explicit_mapping, legend_position = 'top'))\n",
    "\n",
    "##Vertical and Horizontal Lines\n",
    "vline = hv.VLine(100).opts(color = 'black', line_width = 1)\n",
    "hline = hv.HLine(100).opts(color = 'black', line_width = 1)\n",
    "\n",
    "#All Together\n",
    "\n",
    "full_scatter = scatter * vline * hline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the Panel library to be able to save the Table generated\n",
    "p = pn.panel(full_scatter)\n",
    "p.save('ScatterPlot_1Period.html') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For multiple period we need to create a DataFrame with 3-dimensions \n",
    "    #-> to do this we create a dictionary and include each DataFrame with the assigned dictionary key being the Index\n",
    "    \n",
    "indices =  RRG_df.columns.unique()\n",
    "\n",
    "multi_df = dict()\n",
    "for index in indices:\n",
    "    #For each of the Index will do the following procedure\n",
    "    \n",
    "    chosen_columns = []\n",
    "    #This loop is to filter each variable's varlue in the big-dataframe and create a create a single Dataframe\n",
    "    for column in RRG_df[index].columns:\n",
    "        chosen_columns.append(RRG_df[index][column])\n",
    "    joint_table = pd.concat(chosen_columns, axis=1)\n",
    "    \n",
    "    #Change the DataFrame's Header\n",
    "    new_header = joint_table.iloc[0] \n",
    "    joint_table = joint_table[1:] \n",
    "    joint_table.columns = new_header\n",
    "    joint_table = joint_table.loc[:,~joint_table.columns.duplicated()]\n",
    "    \n",
    "    #Remove the first 3 entries\n",
    "    joint_table = joint_table[2:]\n",
    "    \n",
    "    #Create a column for the Index\n",
    "    joint_table['index'] = index\n",
    "    \n",
    "    ##Reset the Index so the Datess are observable the Scatter\n",
    "    joint_table = joint_table.reset_index()\n",
    "    order = [1,2,3,0] # setting column's order\n",
    "    joint_table = joint_table[[joint_table.columns[i] for i in order]]\n",
    "    joint_table = joint_table.rename(columns={\"level_0\": \"Date\"})\n",
    "    joint_table['Date'] = joint_table['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    ##Create a New Column with the Quadrants Indication\n",
    "    joint_table['Quadrant'] = joint_table['index']\n",
    "    for row in joint_table['Quadrant'].index:\n",
    "        if joint_table['JDK_RS_ratio'][row] >= 100 and joint_table['JDK_RS_momentum'][row] >= 100:\n",
    "            joint_table['Quadrant'][row] = 'Leading'\n",
    "        elif joint_table['JDK_RS_ratio'][row] >= 100 and joint_table['JDK_RS_momentum'][row] <= 100:\n",
    "            joint_table['Quadrant'][row] = 'Lagging'\n",
    "        elif joint_table['JDK_RS_ratio'][row] <= 100 and joint_table['JDK_RS_momentum'][row] <= 100:\n",
    "            joint_table['Quadrant'][row] = 'Weakening'\n",
    "        elif joint_table['JDK_RS_ratio'][row] <= 100 and joint_table['JDK_RS_momentum'][row] >= 100:\n",
    "            joint_table['Quadrant'][row] = 'Improving'\n",
    "            \n",
    "    #Joining the obtained Single Dataframes into the Dicitonary\n",
    "    multi_df.update({index: joint_table})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Charts's Area\n",
    "x_y_max = []\n",
    "for Index in multi_df.keys():\n",
    "    x_y_max_ = max(abs(int(multi_df[Index]['JDK_RS_ratio'].min())-100), int(multi_df[Index]['JDK_RS_ratio'].max())-100,\n",
    "                    abs(int(multi_df[Index]['JDK_RS_momentum'].min())-100), int(multi_df[Index]['JDK_RS_momentum'].max())-100)\n",
    "    x_y_max.append(x_y_max_)\n",
    "    \n",
    "x_range = (100 - 1 - max(x_y_max), 100 + 1 + max(x_y_max))\n",
    "y_range = (100 - 1 - max(x_y_max), 100 + 1.25 + max(x_y_max))\n",
    "#Note: y_range has .25 extra on top because legend stays on top and option \"legend_position\" doesn't exist for Overlay graphs\n",
    "\n",
    "#Include Dropdown List\n",
    "def load_indices(Index): \n",
    "    scatter = hv.Scatter(multi_df[Index], kdims = ['JDK_RS_ratio', 'JDK_RS_momentum'])\n",
    "    \n",
    "    ##Colors\n",
    "    explicit_mapping = {'Leading': 'green', 'Lagging': 'yellow', 'Weakening': 'red', 'Improving': 'blue'}\n",
    "    ##Plot Joining all together\n",
    "    scatter = scatter.opts(opts.Scatter(tools=['hover'], height = 500, width=500, size = 10, xlim = x_range, ylim = y_range,\n",
    "                                        color = 'Quadrant', cmap=explicit_mapping,\n",
    "                                       ))\n",
    "    \n",
    "    ##Line connecting the dots\n",
    "    curve = hv.Curve(multi_df[Index], kdims = ['JDK_RS_ratio', 'JDK_RS_momentum'])\n",
    "    curve = curve.opts(opts.Curve(color = 'black', line_width = 1))\n",
    "\n",
    "    ##Vertical and Horizontal Lines\n",
    "    vline = hv.VLine(100).opts(color = 'black', line_width = 1)\n",
    "    hline = hv.HLine(100).opts(color = 'black', line_width = 1)    \n",
    "\n",
    "\n",
    "    #All Together\n",
    "\n",
    "    full_scatter = scatter * vline * hline * curve\n",
    "    full_scatter = full_scatter.opts(legend_cols= True)\n",
    "\n",
    "    return full_scatter\n",
    "        \n",
    "indices_name = RRG_df.columns.drop_duplicates().tolist()\n",
    "\n",
    "#Instantiation the Dynamic Map object\n",
    "dmap = hv.DynamicMap(load_indices, kdims='Index').redim.values(Index=indices_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the Panel library to be able to save the Table generated\n",
    "p = pn.panel(dmap)\n",
    "p.save('ScatterPlot_Multiple_Period.html', embed = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Indices table to html format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Readjust the Table to be Included in Article - not to have all the columns\n",
    "table = indices_data\n",
    "table = table.drop(columns = ['Currency', 'Yahoo Currency Symbol'])\n",
    "\n",
    "#Create the elements for the Table\n",
    "source = ColumnDataSource(table)\n",
    "\n",
    "columns = [TableColumn(field=Ci, title=Ci, width=20) for Ci in table.columns]\n",
    "\n",
    "#Instantiate the Table object\n",
    "data_table = DataTable(source=source, columns=columns, width=800, height=280, selectable = True, index_position = None)\n",
    "\n",
    "#Save the Table using Bokeh library (not Panel, since Holoviews is not used here)\n",
    "output_file('Indices_Table.html')\n",
    "save(data_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
